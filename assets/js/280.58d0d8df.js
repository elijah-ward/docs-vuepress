(window.webpackJsonp=window.webpackJsonp||[]).push([[280],{196:function(e,t,a){"use strict";a.r(t);var n=a(0),s=Object(n.a)({},function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"using-log-filters"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#using-log-filters","aria-hidden":"true"}},[e._v("#")]),e._v(" Using Log Filters")]),e._v(" "),a("p",[e._v("In this tutorial we'll learn how to use Rundeck's log filters to")]),e._v(" "),a("ul",[a("li",[e._v("Capture key value data for use in subsequent jobs")]),e._v(" "),a("li",[e._v("Highlight important output to improve job output readability")]),e._v(" "),a("li",[e._v("Suppress potentially sensitive information from leaking into the logs")])]),e._v(" "),a("h2",{attrs:{id:"use-case-packaging-and-distributing-a-binary"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#use-case-packaging-and-distributing-a-binary","aria-hidden":"true"}},[e._v("#")]),e._v(" Use case: packaging and distributing a binary")]),e._v(" "),a("p",[e._v("To illustrate the log filter functionality, we'll create a project to package and distribute a binary. We'll be using the "),a("a",{attrs:{href:"https://github.com/clofresh/rundeck-playground",target:"_blank",rel:"noopener noreferrer"}},[e._v("Rundeck Playground"),a("OutboundLink")],1),e._v(" environment to simulate a data center locally on your workstation.")]),e._v(" "),a("p",[e._v("A common workflow for distributing binaries is to create an OS package on a builder machine that's optimized for packaging code, upload the built package to a package repository, and then have the destination machines pull the latest version of the package from the repository. In this tutorial, our OS is Ubuntu Linux so we'll be building .deb packages. We'll be using S3 to store the packages. To avoid needing an AWS account when doing the tutorial, we provision a mock S3 server that mirror's S3's API. Lastly, to allow our destination machines to download the package, we'll be passing them a presigned S3 download url which acts as temporary credentials and removes the need for an AWS SDK on the destination machine.")]),e._v(" "),a("p",[e._v("Side note: In a traditional data center, you might just install the AWS CLI tool on the destination host and either authorize that host's IAM role to download from your S3 bucket, or pass a set of AWS credentials from Rundeck's Key Storage to the AWS S3 client at download time. But maybe we have a less common setup, like an IoT deployment of low powered Raspberry Pi's which would struggle to print the help text of the AWS CLI tool.")]),e._v(" "),a("h2",{attrs:{id:"building-the-package"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#building-the-package","aria-hidden":"true"}},[e._v("#")]),e._v(" Building the package")]),e._v(" "),a("p",[e._v("First, we need to create a script to build the package. For convenience, let's say we want to distribute the Hashicorp Consul binary.")]),e._v(" "),a("p",[e._v("First we need to download the binary we want to distribute:")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('$!/bin/bash -xe\n\n# Change to a new temporary directory\ncd $(mktemp -d)\n\n# Create the download url\nNAME=consul\nVERSION="1.2.3"\nURL="https://releases.hashicorp.com/$NAME/${VERSION}/$NAME_${VERSION}_linux_amd64.zip"\n\n# Download the url to the current directory\necho "INFO - Downloading $URL"\ncurl -sOL "$URL"\n\n# Unzip the downloaded file. In this case we know it\'s a single file: the consul binary.\nunzip $(basename "$URL")\n')])])]),a("p",[e._v("Then we need to package the binary into a .deb format. We'll use the very handy "),a("a",{attrs:{href:"https://github.com/jordansissel/fpm",target:"_blank",rel:"noopener noreferrer"}},[e._v("fpm"),a("OutboundLink")],1),e._v(" utility to abstract the gory details into a one-liner:")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('# Call fpm with a directory as the source and a deb as the target. Name the package consul and give it the same version as what we downloaded.\nfpm -s dir -t deb --name "$NAME" --version "$VERSION" "$PKG_DIR"\n')])])]),a("p",[e._v("We want the consul binary to be executable in the system's executable path, so we create that directory structure before calling fpm:")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('PKG_DIR=usr\nmkdir -p "$PKG_DIR/bin"\ninstall ./consul "$PKG_DIR/bin"\nfpm -s dir -t deb --name "$NAME" --version "$VERSION" "$PKG_DIR"\n')])])]),a("p",[e._v("The full script so far looks like:")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('$!/bin/bash -xe\n\n# Change to a new temporary directory\ncd $(mktemp -d)\n\n# Create the download url\nNAME=consul\nVERSION="1.2.3"\nURL="https://releases.hashicorp.com/$NAME/${VERSION}/$NAME_${VERSION}_linux_amd64.zip"\n\n# Download the url to the current directory\necho "INFO - Downloading $URL"\ncurl -sOL "$URL"\n\n# Unzip the downloaded file. In this case we know\nit\'s a single file: the consul binary.\necho "INFO - Packaging $NAME version $VERSION"\nunzip $(basename "$URL")\n\n# Create the appropriate directory structure\nPKG_DIR=usr\nmkdir -p "$PKG_DIR/bin"\ninstall ./consul "$PKG_DIR/bin"\n\n# Call fpm with a directory as the source and a deb as the target. Name the package consul and give it the same version as what we downloaded.\nfpm -s dir -t deb --name "$NAME" --version "$VERSION" --deb-no-default-config-files "$PKG_DIR"\n')])])]),a("p",[e._v("If you run that you might get:")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('+ fpm -s dir -t deb --name consul --version 1.2.3 --deb-no-default-config-files usr\nCreated package {:path=>"consul_1.2.3_amd64.deb"}\n')])])]),a("p",[e._v('"Oh," you might be thinking, "Maybe I should use the Key Value Data log filter to capture that path output to capture that outputed filename to pass to an upload script."')]),e._v(" "),a("p",[e._v("You could do that, especially if you had a custom script plugin to do uploads. However for this tutorial, we'll just do the uploading from the same script, so we'll capture the outputted filename like this:")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('DEB_FILE=$(fpm -s dir -t deb --name "$NAME" --version "$VERSION" --deb-no-default-config-files  "$PKG_DIR" \\\n    | ruby -e \'puts eval(STDIN.read)[:path]\')\n')])])]),a("p",[e._v("Here we're piping the fpm output into a Ruby snippet to parse the map and print out the path key, which we capture in the DEB_FILE bash variable.")]),e._v(" "),a("p",[e._v("Now we upload the .deb file using the AWS CLI tool and a set of AWS credentials passed into the script:")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('S3_URL="s3://rundeck-playground/consul/${DEB_FILE}"\necho "INFO - Uploading $DEB_FILE to $S3_URL"\nexport AWS_ACCESS_KEY_ID=$1\nset +x # Don\'t log the secret key\nexport AWS_SECRET_ACCESS_KEY=$2\nset -x # Continue verbose bash logging\naws s3 cp --quiet "$DEB_FILE" "$S3_URL"\n')])])]),a("p",[e._v("In the Rundeck Playground environment, you don't need to create the bucket beforehand because it's a mock s3 server, but in the real AWS environment, you do.")]),e._v(" "),a("p",[e._v("Lastly, we want to generate a presigned url that we want Rundeck to pass to the destination nodes that will install the package. To do that:")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('echo "INFO - Generating presigned url for $S3_URL"\nDOWNLOAD_URL=$(aws s3 presign "$S3_URL")\necho "RUNDECK:DATA:DOWNLOAD_URL = $DOWNLOAD_URL"\necho "RUNDECK:DATA:DEB_FILE = $DEB_FILE"\n')])])]),a("p",[e._v("The "),a("code",[e._v("aws s3 presign")]),e._v(" command takes an S3 path that you have access to and creates a url that anyone can read from but expires in a fixed amount of time, in this case the default is 1 hour. It prints out the presigned url which we capture in the DOWNLOAD_URL bash variable.")]),e._v(" "),a("p",[e._v("Now, we print out the variables we want to use in subsequent Rundeck steps in a format that Rundeck can capture: "),a("code",[e._v("RUNDECK:DATA:$VARIABLE = $VALUE")])]),e._v(" "),a("p",[e._v("The full build.sh script:")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('#!/bin/bash -xe\n\nS3_BASE=rundeck-playground/consul/\n\ncd $(mktemp -d)\n\n_pkgdir="pkg"\n\nNAME=consul\nBIN_NAME=${BIN_NAME-$NAME}\nVERSION="1.2.3"\nURL="https://releases.hashicorp.com/consul/${VERSION}/consul_${VERSION}_linux_amd64.zip"\n\nmkdir -p "$_pkgdir"\n\necho "INFO - Downloading $URL"\ncurl -sOL "$URL"\n\necho "INFO - Packaging $NAME version $VERSION"\nunzip $(basename "$URL")\ntouch $BIN_NAME\nmkdir -p "${_pkgdir}/usr/bin"\ninstall "$BIN_NAME" "${_pkgdir}/usr/bin"\ncd ${_pkgdir}\nDEB_FILE=$(fpm -s dir -t deb --name "$NAME" --version "$VERSION" . | ruby -e \'puts eval(STDIN.read)[:path]\')\n\nS3_URL="s3://${S3_BASE%%/*}/${DEB_FILE}"\necho "INFO - Uploading $DEB_FILE to $S3_URL"\nexport AWS_ACCESS_KEY_ID=$1\nset +x\nexport AWS_SECRET_ACCESS_KEY=$2\nset -x\naws s3 cp --quiet "$DEB_FILE" "$S3_URL"\n\necho "INFO - Generating presigned url for $S3_URL"\necho -n "RUNDECK:DATA:DOWNLOAD_URL = "\naws s3 presign "$S3_URL"\necho "RUNDECK:DATA:DEB_FILE = $DEB_FILE"\n')])])]),a("h2",{attrs:{id:"wrap-the-build-script-in-a-custom-script-step-plugin"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#wrap-the-build-script-in-a-custom-script-step-plugin","aria-hidden":"true"}},[e._v("#")]),e._v(" Wrap the build script in a custom script step plugin")]),e._v(" "),a("p",[e._v("To trigger build script we just created, we could use a Rundeck script step. However, since the script needs credentials, it's better practice to wrap the script in a custom script step plugin so that you can securely pass secrets from Key Storage into the script.")]),e._v(" "),a("p",[e._v("The build script's plugin.yaml would look like:")]),e._v(" "),a("div",{staticClass:"language-{.yaml} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('name: deb builder\nversion: 1\nrundeckPluginVersion: 1.2\nauthor: Carlo Cabanilla\ndate: 2018-09-21\nurl: http://rundeck.org/\nproviders:\n  - name: BuildDeb\n    service: RemoteScriptNodeStep\n    plugin-type: script\n    script-interpreter: /bin/bash -xe\n    script-file: build.sh\n    script-args: ${config.aws_access_key_id} ${config.aws_secret_access_key}\n    config:\n      - name: aws_access_key_id\n        type: String\n        renderingOptions:\n          valueConversion: "STORAGE_PATH_AUTOMATIC_READ"\n      - name: aws_secret_access_key\n        type: String\n        renderingOptions:\n          valueConversion: "STORAGE_PATH_AUTOMATIC_READ"\n')])])]),a("p",[e._v("Note the "),a("code",[e._v('renderingOptions:valueConversion: "STORAGE_PATH_AUTOMATIC_READ"')]),e._v(" settings on the credential values. That lets us pass in Key Storage paths and the plugin will pull the values and pass it into the script. For a more detailed tutorial on custom script step plugins, see (/tutorials/custom-script-plugin-hello-world.md).")]),e._v(" "),a("h2",{attrs:{id:"create-the-job"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#create-the-job","aria-hidden":"true"}},[e._v("#")]),e._v(" Create the job")]),e._v(" "),a("p",[e._v("Now we need a job to trigger the script step. It might look like this:")]),e._v(" "),a("div",{staticClass:"language-{.yaml} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("- uuid: PackageDeb\n  name: PackageDeb\n  nodefilters:\n    filter: fpm\n  sequence:\n    commands:\n    - type: BuildDeb\n      nodeStep: true\n      configuration:\n        aws_access_key_id: keys/projects/hello-project/aws/access-key-id\n        aws_secret_access_key: keys/projects/hello-project/aws/secret-access-key\n")])])]),a("p",[e._v("The new config here are the Key Storage paths to the AWS credentials and the nodefilter to select the node to run the build.")]),e._v(" "),a("h2",{attrs:{id:"highlighting-high-level-log-output"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#highlighting-high-level-log-output","aria-hidden":"true"}},[e._v("#")]),e._v(" Highlighting high level log output")]),e._v(" "),a("p",[e._v("If we test it out in the web UI, the output might look like:")]),e._v(" "),a("p",[a("img",{attrs:{src:"/figures/log-highlight-none.png",alt:"Without highlighting"}})]),e._v(" "),a("p",[e._v("Here we can apply our first log filter to call out our high level logging output so that it stands out from the low level script commands.")]),e._v(" "),a("div",{staticClass:"language-{.yaml} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("- uuid: PackageDeb\n  name: PackageDeb\n  nodefilters:\n    filter: fpm\n  sequence:\n    pluginConfig:\n      LogFilter:\n      - type: highlight-output\n        config:\n          bgcolor: yellow\n          mode: bold\n          regex: ^INFO\\s*-\\s*(.*)$\n    commands:\n    - type: BuildDeb\n      nodeStep: true\n      configuration:\n        aws_access_key_id: keys/projects/hello-project/aws/access-key-id\n        aws_secret_access_key: keys/projects/hello-project/aws/secret-access-key\n")])])]),a("p",[a("img",{attrs:{src:"/figures/log-highlight-bold.png",alt:"With highlighting"}})]),e._v(" "),a("p",[e._v("Now we can more easily skim the log output for the important steps.")]),e._v(" "),a("h2",{attrs:{id:"prevent-accidental-leakage-of-secrets"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#prevent-accidental-leakage-of-secrets","aria-hidden":"true"}},[e._v("#")]),e._v(" Prevent accidental leakage of secrets")]),e._v(" "),a("p",[e._v("Remember this snippet of our build script?")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("set +x\nexport AWS_SECRET_ACCESS_KEY=$2\nset -x\n")])])]),a("p",[e._v("Since we're running the script with "),a("code",[e._v("bash -x")]),e._v(", it prints out each command that it's running and the values of the variables we assign. The above snippet explictly suppresses that verbose logging when we set the secret key to avoid exposing it in the logs.")]),e._v(" "),a("p",[e._v("What if we didn't have the foresight to supress that output? Could we prevent ourselves from shooting ourselves in the foot?")]),e._v(" "),a("p",[e._v("We can partially protect ourselves using the "),a("code",[e._v("quiet-output")]),e._v(" log filter:")]),e._v(" "),a("div",{staticClass:"language-{.yaml} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("  sequence:\n    pluginConfig:\n      LogFilter:\n      - type: quiet-output\n        config:\n          loglevel: debug\n          matchLoglevel: all\n          quietMatch: 'true'\n          regex: AWS_SECRET_ACCESS_KEY\n")])])]),a("p",[e._v("Here we're saying at any log level, if you see the string "),a("code",[e._v("AWS_SECRET_ACCESS_KEY")]),e._v(", change that log line's log level to debug. This would have prevented us leaking the the key from "),a("code",[e._v("bash -x")]),e._v(" output, assuming we were running under the default log level. However, the filter wouldn't hide it if you ran it with the debug log level.")]),e._v(" "),a("p",[e._v("Additionally, it won't prevent something like:")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("echo $AWS_SECRET_ACCESS_KEY\n")])])]),a("p",[e._v("Because "),a("code",[e._v("bash -x")]),e._v(" logging would have evaluated the variable already and it will show up as:")]),e._v(" "),a("div",{staticClass:"language-{.bash} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("+ echo whatever_the_value_is\n")])])]),a("p",[e._v("So while the "),a("code",[e._v("quiet-output")]),e._v(" shouldn't be your main protection from hiding secrets, it's another possible safeguard and better than nothing.")]),e._v(" "),a("h2",{attrs:{id:"running-jobs-on-different-sets-of-nodes"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#running-jobs-on-different-sets-of-nodes","aria-hidden":"true"}},[e._v("#")]),e._v(" Running jobs on different sets of nodes")]),e._v(" "),a("p",[e._v("We want to install the package on different nodes than we built it on, but there's no way to specify a different set of nodes for different steps, so how can we proceed?")]),e._v(" "),a("p",[e._v("We can create another job to install the package and reference the build job to trigger the build. Here is the new job:")]),e._v(" "),a("div",{staticClass:"language-{.yaml} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('- name: InstallDeb\n  nodefilters:\n    filter: web_.*\n  sequence:\n    commands:\n    - jobref:\n        uuid: PackageDeb\n    - script: |\n        #!/bin/bash -xe\n        WORKING_DIR=$(mktemp -d)\n        echo "INFO - Downloading $2 to $WORKING_DIR"\n        cd $WORKING_DIR\n        curl -sL "$1" > $2\n        echo "INFO - Installing $2"\n        dpkg -i "$2"\n        rm "$2"\n')])])]),a("p",[e._v("The new node filter points to the web nodes, our destination for the package.")]),e._v(" "),a("p",[a("code",[e._v("jobref")]),e._v(" lets us call other jobs and let them use their own node filter. In this case we call PackageDeb to package the deb on the fpm node.")]),e._v(" "),a("p",[e._v("The second step is an inline script to download and install the package. We don't need to wrap it in a custom script step plugin because there's no credentials to deal with.")]),e._v(" "),a("h2",{attrs:{id:"passing-data-from-one-job-to-another"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#passing-data-from-one-job-to-another","aria-hidden":"true"}},[e._v("#")]),e._v(" Passing data from one job to another")]),e._v(" "),a("p",[e._v("But wait, how does this job know what the download url and the name of the package file are? At last, this is where the key value log filter comes into play:")]),e._v(" "),a("div",{staticClass:"language-{.yaml} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('- name: InstallDeb\n  nodefilters:\n    filter: web_.*\n  sequence:\n    pluginConfig:\n      LogFilter:\n      - type: key-value-data\n        config:\n          logData: \'false\'\n          regex: ^RUNDECK:DATA:(.+?)\\s*=\\s*(.+)$\n    commands:\n    - jobref:\n        uuid: PackageDeb\n    - args: ${data.DOWNLOAD_URL} ${data.DEB_FILE}\n      script: |\n        #!/bin/bash -xe\n        WORKING_DIR=$(mktemp -d)\n        echo "INFO - Downloading $2 to $WORKING_DIR"\n        cd $WORKING_DIR\n        curl -sL "$1" > $2\n        echo "INFO - Installing $2"\n        dpkg -i "$2"\n        rm "$2"\n')])])]),a("p",[e._v("Here we define a regex to capture that simple format we used in the build script. The variables get stored in the "),a("code",[e._v("data")]),e._v(" context where we can refer to them later on in the job.")]),e._v(" "),a("p",[e._v("However! If the InstallDeb's own log output printed out "),a("code",[e._v("RUNDECK:DATA:DOWNLOAD_URL = ...")]),e._v(" then this would work, but the above configuration won't work because the parent job doesn't have access to the job reference's data.")]),e._v(" "),a("p",[e._v("Instead, we need to export the variables from the build job so that the install job has access to them. Modifying the PackageDeb job:")]),e._v(" "),a("div",{staticClass:"language-{.yaml} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("- uuid: PackageDeb\n  name: PackageDeb\n  nodefilters:\n    filter: fpm\n  sequence:\n    pluginConfig:\n      LogFilter:\n      - type: key-value-data\n        config:\n          logData: 'true'\n          regex: ^RUNDECK:DATA:(.+?)\\s*=\\s*(.+)$\n    commands:\n    - type: BuildDeb\n      nodeStep: true\n      configuration:\n        aws_access_key_id: keys/projects/hello-project/aws/access-key-id\n        aws_secret_access_key: keys/projects/hello-project/aws/secret-access-key\n    - type: export-var\n      nodeStep: false\n      configuration:\n        export: DOWNLOAD_URL\n        group: export\n        value: ${data.DOWNLOAD_URL@fpm}\n    - type: export-var\n      nodeStep: false\n      configuration:\n        export: DEB_FILE\n        group: export\n        value: ${data.DEB_FILE@fpm}\n")])])]),a("p",[e._v("The key here is the "),a("code",[e._v("export-var")]),e._v(" steps to move the "),a("code",[e._v("data.DOWNLOAD_URL")]),e._v(" and "),a("code",[e._v("data.DEB_FILE")]),e._v(" values captured with the "),a("code",[e._v("key-value-data")]),e._v(" log filter into the "),a("code",[e._v("export")]),e._v(" global variable group.")]),e._v(" "),a("p",[e._v("Now our InstallDeb job can use those global variables:")]),e._v(" "),a("div",{staticClass:"language-{.yaml} extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('- name: InstallDeb\n  nodefilters:\n    filter: web_.*\n  sequence:\n    commands:\n    - jobref:\n        uuid: PackageDeb\n    - args: ${export.DOWNLOAD_URL} ${export.DEB_FILE}\n      script: |\n        #!/bin/bash -xe\n        WORKING_DIR=$(mktemp -d)\n        echo "INFO - Downloading $2 to $WORKING_DIR"\n        cd $WORKING_DIR\n        curl -sL "$1" > $2\n        echo "INFO - Installing $2"\n        dpkg -i "$2"\n        rm "$2"\n')])])]),a("p",[e._v("And now the web nodes have the presigned url generated by the fpm node. Magic!")]),e._v(" "),a("p",[e._v("To recap, running this job would:")]),e._v(" "),a("ul",[a("li",[e._v("Run a script on a build node to package a binary into a deb and securely upload it to S3.")]),e._v(" "),a("li",[e._v("Pass a temporary url from the build node to let a different set of nodes without AWS credentials or a special S3 client download and install the package.")])])])},[],!1,null,null,null);t.default=s.exports}}]);